services:
  # FastAPI Backend (Development)
  mysqlens-api:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: mysqlens-api-dev
    environment:
      # LLM Provider Configuration (Ollama is default for privacy)
      - LLM_PROVIDER=${LLM_PROVIDER:-ollama}

      # Ollama Configuration (Local LLM - Recommended)
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://host.docker.internal:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.2:latest}

      # Cloud LLM Providers (Optional)
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY}

      # Backend Configuration
      - BACKEND_HOST=0.0.0.0
      - BACKEND_PORT=8080
      - BACKEND_RELOAD=true

      # Application Settings
      - ENVIRONMENT=development
      - DEBUG=true
      - LOG_LEVEL=INFO

      # Cache Configuration
      - CACHE_TTL=3600
      - CACHE_SIZE=1000

      # Analysis Configuration
      - POLLING_INTERVAL=30
      - TOP_QUERIES_LIMIT=50
      - ANALYSIS_INTERVAL=60
    ports:
      - "8080:8080"
    volumes:
      - ./backend:/app
      - api_cache:/app/cache
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - mysqlens-network
    command: python main.py

  # Next.js Frontend (Development)
  mysqlens-ui:
    image: node:20-alpine
    container_name: mysqlens-ui-dev
    working_dir: /app
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:8080
      - BACKEND_URL=http://mysqlens-api:8080
      - NODE_ENV=development
    ports:
      - "3000:3000"
    volumes:
      - ./frontend:/app
      - /app/node_modules
      - /app/.next
    depends_on:
      - mysqlens-api
    networks:
      - mysqlens-network
    command: sh -c "npm install && npm run dev"

volumes:
  api_cache:
    driver: local

networks:
  mysqlens-network:
    driver: bridge

