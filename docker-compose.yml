services:
  # FastAPI Backend
  mysqlens-api:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: mysqlens-api
    environment:
      # LLM Provider Configuration (Ollama is default for privacy)
      - LLM_PROVIDER=${LLM_PROVIDER:-ollama}

      # Ollama Configuration (Local LLM - Recommended)
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://host.docker.internal:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.2:latest}

      # Cloud LLM Providers (Optional)
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY}

      # Backend Configuration
      - BACKEND_HOST=${BACKEND_HOST:-0.0.0.0}
      - BACKEND_PORT=${BACKEND_PORT:-8080}
      - BACKEND_RELOAD=${BACKEND_RELOAD:-false}

      # Application Settings
      - ENVIRONMENT=${ENVIRONMENT:-production}
      - DEBUG=${DEBUG:-false}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}

      # Cache Configuration
      - CACHE_TTL=${CACHE_TTL:-3600}
      - CACHE_SIZE=${CACHE_SIZE:-1000}

      # Analysis Configuration
      - POLLING_INTERVAL=${POLLING_INTERVAL:-30}
      - TOP_QUERIES_LIMIT=${TOP_QUERIES_LIMIT:-50}
      - ANALYSIS_INTERVAL=${ANALYSIS_INTERVAL:-60}
    ports:
      - "8080:8080"
    volumes:
      - ./backend:/app
      - api_cache:/app/cache
      - ./db-config.json:/app/db-config.json
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - mysqlens-network
    restart: unless-stopped

  # Next.js Frontend
  mysqlens-ui:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: mysqlens-ui
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:8080
      - BACKEND_URL=http://mysqlens-api:8080
      - NODE_ENV=production
    ports:
      - "3000:3000"
    depends_on:
      - mysqlens-api
    networks:
      - mysqlens-network
    restart: unless-stopped

volumes:
  api_cache:
    driver: local

networks:
  mysqlens-network:
    driver: bridge
